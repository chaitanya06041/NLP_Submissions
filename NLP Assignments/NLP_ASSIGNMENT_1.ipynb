{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8kAR1V_YrJP",
        "outputId": "4b77fa83-0544-4302-e0cf-fe4d84624264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import (word_tokenize, WordPunctTokenizer, TreebankWordTokenizer,\n",
        "                           TweetTokenizer, MWETokenizer)\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "text = \"don't Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural language generation (frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.\"\n"
      ],
      "metadata": {
        "id": "FkoqCKbVZZiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Whitespace Tokenization\n",
        "whitespace_tokens = text.split()\n",
        "print(\"Whitespace Tokenization:\", whitespace_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEczAwfnZ5b9",
        "outputId": "3873d75f-461c-48ec-cda1-73aa4128aaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whitespace Tokenization: [\"don't\", 'Natural', 'language', 'processing', '(NLP)', 'is', 'a', 'field', 'of', 'computer', 'science,', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(natural)', 'languages,', 'and,', 'in', 'particular,', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding,', 'natural', 'language', 'generation', '(frequently', 'from', 'formal,', 'machine-readable', 'logical', 'forms),', 'connecting', 'language', 'and', 'machine', 'perception,', 'managing', 'human-computer', 'dialog', 'systems,', 'or', 'some', 'combination', 'thereof.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Punctuation-based Tokenization\n",
        "word_punct_tokens = WordPunctTokenizer().tokenize(text)\n",
        "print(\"Punctuation-based Tokenization:\", word_punct_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfyyzUd3Z-_1",
        "outputId": "d6288af3-b219-4758-c688-a9bb504c9f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation-based Tokenization: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', '(', 'frequently', 'from', 'formal', ',', 'machine', '-', 'readable', 'logical', 'forms', '),', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human', '-', 'computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_punct_tokens = nltk.wordpunct_tokenize(text)\n",
        "print(word_punct_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1S6drvDa2JV",
        "outputId": "484ed272-8fc6-4708-b2a3-07c37646881c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['running', 'better', 'jumping', 'ran']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Treebank Tokenization\n",
        "treebank_tokens = TreebankWordTokenizer().tokenize(text)\n",
        "print(\"Treebank Tokenization:\", treebank_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZpzocTpbFnV",
        "outputId": "e219aa3d-713c-4412-c586-c049df918e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treebank Tokenization: ['do', \"n't\", 'Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', '(', 'frequently', 'from', 'formal', ',', 'machine-readable', 'logical', 'forms', ')', ',', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human-computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Tweet Tokenization\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(text)\n",
        "print(\"Tweet Tokenization:\", tweet_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWGDHadUbs9N",
        "outputId": "0df69899-d38b-4061-ad63-03dc9e6fbfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet Tokenization: [\"don't\", 'Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', '(', 'frequently', 'from', 'formal', ',', 'machine-readable', 'logical', 'forms', ')', ',', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human-computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Multi-Word Expression Tokenization\n",
        "tokenizer = MWETokenizer()\n",
        "tokenizer.add_mwe((\"Natural\", \"language\", \"processing\"))\n",
        "tokenizer.add_mwe((\"artificial\", \"intelligence\"))\n",
        "mwe_tokens = tokenizer.tokenize(word_tokenize(text))\n",
        "print(\"MWE Tokenization:\", mwe_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAfIsqwOb-W0",
        "outputId": "47fe3f0b-53d3-467d-b285-582a6cc16ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MWE Tokenization: ['do', \"n't\", 'Natural_language_processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial_intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', '(', 'frequently', 'from', 'formal', ',', 'machine-readable', 'logical', 'forms', ')', ',', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human-computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter Stemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "porter_stems = [porter_stemmer.stem(token) for token in word_tokenize(text)]\n",
        "print(\"Porter Stemmer:\", porter_stems)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXXJrlOnfLs9",
        "outputId": "ddd1c5ae-003d-4693-8a11-4cde3491a9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer: ['natur', 'languag', 'process', '(', 'nlp', ')', 'is', 'a', 'field', 'of', 'comput', 'scienc', ',', 'artifici', 'intellig', 'and', 'comput', 'linguist', 'concern', 'with', 'the', 'interact', 'between', 'comput', 'and', 'human', '(', 'natur', ')', 'languag', ',', 'and', ',', 'in', 'particular', ',', 'concern', 'with', 'program', 'comput', 'to', 'fruit', 'process', 'larg', 'natur', 'languag', 'corpora', '.', 'challeng', 'in', 'natur', 'languag', 'process', 'frequent', 'involv', 'natur', 'languag', 'understand', ',', 'natur', 'languag', 'gener', '(', 'frequent', 'from', 'formal', ',', 'machine-read', 'logic', 'form', ')', ',', 'connect', 'languag', 'and', 'machin', 'percept', ',', 'manag', 'human-comput', 'dialog', 'system', ',', 'or', 'some', 'combin', 'thereof', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Snowball Stemmer\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "snowball_stems = [snowball_stemmer.stem(token) for token in word_tokenize(text)]\n",
        "print(\"Snowball Stemmer:\", snowball_stems)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfSFl8k7ff7E",
        "outputId": "7b6d4798-16d0-4e52-b2b0-5fb12258e7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snowball Stemmer: ['natur', 'languag', 'process', '(', 'nlp', ')', 'is', 'a', 'field', 'of', 'comput', 'scienc', ',', 'artifici', 'intellig', 'and', 'comput', 'linguist', 'concern', 'with', 'the', 'interact', 'between', 'comput', 'and', 'human', '(', 'natur', ')', 'languag', ',', 'and', ',', 'in', 'particular', ',', 'concern', 'with', 'program', 'comput', 'to', 'fruit', 'process', 'larg', 'natur', 'languag', 'corpora', '.', 'challeng', 'in', 'natur', 'languag', 'process', 'frequent', 'involv', 'natur', 'languag', 'understand', ',', 'natur', 'languag', 'generat', '(', 'frequent', 'from', 'formal', ',', 'machine-read', 'logic', 'form', ')', ',', 'connect', 'languag', 'and', 'machin', 'percept', ',', 'manag', 'human-comput', 'dialog', 'system', ',', 'or', 'some', 'combin', 'thereof', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "e-T3jUWcfh_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get POS tag for lemmatization\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "q8oYTg8YfmvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"running better jumping ran\""
      ],
      "metadata": {
        "id": "Nn40avf7kTQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in word_tokenize(text)]\n",
        "print(\"Lemmatized Words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRhisZ6BfqAE",
        "outputId": "e53a1745-3a49-4b81-81d3-9fcaea59b457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['run', 'well', 'jumping', 'ran']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnl = WordNetLemmatizer()\n",
        "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
        "\n",
        "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Lemma--\"))\n",
        "for word in example_words:\n",
        "   print (\"{0:20}{1:20}\".format(word, wnl.lemmatize(word, pos=\"v\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u01e5kdplU9i",
        "outputId": "c99b35a0-289c-4694-8bcd-1d25b5a497ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Word--            --Lemma--           \n",
            "program             program             \n",
            "programming         program             \n",
            "programer           programer           \n",
            "programs            program             \n",
            "programmed          program             \n"
          ]
        }
      ]
    }
  ]
}